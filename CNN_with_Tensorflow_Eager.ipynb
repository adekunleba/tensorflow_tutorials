{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN with Tensorflow Eager.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adekunleba/tensorflow_tutorials/blob/master/CNN_with_Tensorflow_Eager.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "UHcORc5hKEAu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Learning to write Convolution Neural Networks with Tensorflow Eager Execution and Tf.keras API"
      ]
    },
    {
      "metadata": {
        "id": "QZESuKQS4gMh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-b8YIY5T5N77",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using MNIST Data can we do a tf.eager project to build a Model using Convolutional Neural Network.\n",
        "\n",
        "The major focus of this project is to adapt tf.eager in the process of training machine learning, right from data generation and converting the DataSet which is the format that is recommended by tensorflow to passing the data to the model and computing gradients on the data as the training goes on.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "_AAsp7z342ju",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3PJRlXnC5ZTh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# input_data.read_data_sets()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UqcY1hz8jV-4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Mnist from keras datasets presents you with a way to get data first, it comes already prepared with the data and the label. In some other custom cases, you might need to define the data generator approach to get your data and read it into the dataset.\n",
        "\n",
        "However, as smooth as the data from mnist is, it is also important to note that we had to convert a numpy array which is the format which the data from mnist is, to a Dataset,\n",
        "\n",
        "Also, the labels existed as the corresponding figure, we needed to convert this to a one-hot approach with the help of `tf.one_hot` we are able to convert a numpy list of corresponding digit values to a one-hot encoding.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "9Lf740sCm6Gt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "8bmFk16P5dLP",
        "colab_type": "code",
        "outputId": "d7a9b9d9-a22b-4da8-e20d-8d62784dcfc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((-1, 28, 28, 1))\n",
        "x_test = x_test.reshape((-1, 28, 28, 1))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fI4UCLAC6abH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#x_train is a numpy array of `(60000, 28, 28, 1)`"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EQJ5Z4cL6nxo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#convert array to one hot with tensorflow\n",
        "num_classes = 10\n",
        "y_train = tf.one_hot(y_train, depth=num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y_z6-moQ6cLt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test = tf.one_hot(y_test, depth=num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vgFlGqukk9h3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using `tf.data.Dataset.from_tensor_slices` we can then get the numpy array of`images` and `labels` into a Dataset.\n",
        "\n",
        "*Note that we can apply many other `map` functions to the datase if we find need of it.*\n",
        "\n",
        "\n",
        "The interesting thing about dataset is also the ability to easily batch, hence on the call to `batch`, tensorflow takes care of batching the data to model.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "nB_SQki-8Q1x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train.numpy()))\n",
        "train_dataset = train_dataset.batch(32)\n",
        "\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test.numpy()))\n",
        "test_dataset = test_dataset.batch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ry_fy6gFISJL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using Model subclassing API, this is an imperative approach introduced into Tensorflow. It allows enough flexibility and quick changes to the architecutre.\n",
        "\n",
        "With this, you can control the approach of the forward pass of the data through your network. I have found this to be more usefull when trying out new Ideas. \n",
        "\n",
        "It's"
      ]
    },
    {
      "metadata": {
        "id": "gnVKhz278xT9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Build your CNN Model\n",
        "\n",
        "class ConvBN(tf.keras.Model):\n",
        "  \n",
        "  def __init__(self, filters, size, apply_batchnorm=True, apply_pooling=False):\n",
        "    super(ConvBN, self).__init__()\n",
        "    self.apply_batchnorm = apply_batchnorm\n",
        "    self.apply_pooling = apply_pooling\n",
        "    initializer = tf.random_normal_initializer(0, 0.02)\n",
        "    \n",
        "    self.conv = tf.keras.layers.Conv2D(filters, (size, size), strides=2, padding=\"same\",\n",
        "                                       kernel_initializer=initializer, use_bias=False)\n",
        "    self.batchnorm = tf.keras.layers.BatchNormalization()\n",
        "    self.dropout = tf.keras.layers.Dropout(0.5)\n",
        "    self.pool = tf.keras.layers.GlobalAveragePooling2D()\n",
        "    \n",
        "    \n",
        "  def call(self, inputs, training):\n",
        "    x = self.conv(inputs)\n",
        "    if self.apply_batchnorm:\n",
        "      x = self.batchnorm(x, training=training)\n",
        "    if self.apply_pooling:\n",
        "      x = self.pool(x)\n",
        "    x = tf.nn.relu(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yrRGJ4MQ9T1x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MNISTCNN(tf.keras.Model):\n",
        "  \n",
        "  def __init__(self, num_classes):\n",
        "    super(MNISTCNN, self).__init__()\n",
        "    self.conv1 = ConvBN(64, 4)\n",
        "    self.conv2 = ConvBN(128, 4, apply_pooling=False)\n",
        "    self.conv3 = ConvBN(128, 4, apply_pooling=False)\n",
        "    \n",
        "    self.flatten = tf.keras.layers.Flatten()\n",
        "    self.last = tf.keras.layers.Dense(num_classes)\n",
        "  \n",
        "  @tf.contrib.eager.defun\n",
        "  def call(self, inputs, training):\n",
        "    x = self.conv1(inputs, training=training)\n",
        "    x = self.conv2(x, training=training)\n",
        "    x = self.conv3(x, training=training)\n",
        "    \n",
        "    \n",
        "    last = self.last(self.flatten(x))\n",
        "    return last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "miR9dR9gNu6s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = MNISTCNN(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oRmfMe5iIY1z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model.fit_generator() Tensorflow Model Subclassing also have the ability to fit on a generator."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lykM6LxvgQyf",
        "colab_type": "code",
        "outputId": "6d22de24-03c5-4c89-8d7b-51edb3f7933a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_bn (ConvBN)             multiple                  1280      \n",
            "_________________________________________________________________\n",
            "conv_bn_1 (ConvBN)           multiple                  131584    \n",
            "_________________________________________________________________\n",
            "conv_bn_2 (ConvBN)           multiple                  262656    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  20490     \n",
            "=================================================================\n",
            "Total params: 416,010\n",
            "Trainable params: 415,370\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aCeokGLOIPll",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Teh"
      ]
    },
    {
      "metadata": {
        "id": "U_A-CUcmIOca",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "acjh48OTE9mP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Train the model\n",
        "\n",
        "#define optimizer \n",
        "optimizer = tf.train.AdamOptimizer(2e-4, beta1=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vngFVZ9VJAT2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "#Set up checkpoints\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J94Mq7xZMhlT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gradient_loss(logits, one_hot_labels):\n",
        "  return tf.losses.softmax_cross_entropy(logits=logits, onehot_labels=one_hot_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-WXDso-d5-Hk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Write code to always see the prediction. The Test part of the deal\n",
        "\n",
        "def generate_test(model, input, target):\n",
        "  prediction = model(input, training=True)\n",
        "  #prediction is (1, 10)\n",
        "  print(\"model predicted {} while actual image is {}\".format())\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vgrcuww7KO65",
        "colab_type": "code",
        "outputId": "5a518bab-1465-4dc5-8a7e-53ef90c449a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "EPOCHS = 200\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "  \n",
        "  for input_image, target in train_dataset:\n",
        "    with tf.GradientTape() as tape:\n",
        "            \n",
        "      logits = model(input_image, training=True) #Run a foward pass\n",
        "      loss = gradient_loss(logits=logits, one_hot_labels=target) #Note target was already in one-hot encoding\n",
        "      \n",
        "    gradients = tape.gradient(loss, model.variables)\n",
        "    \n",
        "    \n",
        "    #Do Optimization\n",
        "    optimizer.apply_gradients(zip(gradients, model.variables))\n",
        "  \n",
        "  \n",
        "  if epoch % 2 == 0:\n",
        "    for test_image, tar in test_dataset.take(1):\n",
        "      prediction = model(test_image, training=True)\n",
        "      print(\"model predicted {} while actual image is {}\".format(np.argmax(prediction), np.argmax(tar)))\n",
        "      \n",
        "  \n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    print ('Time taken for epoch {} is {} sec\\n'.format(epoch,\n",
        "                                                          time.time()-start))\n",
        "      \n",
        "      \n",
        "      #Tape needs Gradient.\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-3e40930f4dae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Note target was already in one-hot encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-2783b4454057>\u001b[0m in \u001b[0;36mgradient_loss\u001b[0;34m(logits, one_hot_labels)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgradient_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monehot_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mone_hot_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py\u001b[0m in \u001b[0;36msoftmax_cross_entropy\u001b[0;34m(onehot_labels, logits, weights, label_smoothing, scope, loss_collection, reduction)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m     return compute_weighted_loss(\n\u001b[0;32m--> 808\u001b[0;31m         losses, weights, scope, loss_collection, reduction=reduction)\n\u001b[0m\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py\u001b[0m in \u001b[0;36mcompute_weighted_loss\u001b[0;34m(losses, weights, scope, loss_collection, reduction)\u001b[0m\n\u001b[1;32m    223\u001b[0m         elif (reduction == Reduction.SUM_BY_NONZERO_WEIGHTS or\n\u001b[1;32m    224\u001b[0m               reduction == Reduction.SUM_OVER_NONZERO_WEIGHTS):\n\u001b[0;32m--> 225\u001b[0;31m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_num_present\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mReduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSUM_OVER_BATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_num_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py\u001b[0m in \u001b[0;36m_num_present\u001b[0;34m(losses, weights, per_batch)\u001b[0m\n\u001b[1;32m    139\u001b[0m   if ((isinstance(weights, float) and weights != 0.0) or\n\u001b[1;32m    140\u001b[0m       (context.executing_eagerly() and weights._rank() == 0  # pylint: disable=protected-access\n\u001b[0;32m--> 141\u001b[0;31m        and not math_ops.equal(weights, 0.0))):\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_num_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"num_present\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mequal\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   2745\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m   2746\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Equal\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2747\u001b[0;31m         _ctx._post_execution_callbacks, x, y)\n\u001b[0m\u001b[1;32m   2748\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2749\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "YZK_7sfsOF2U",
        "colab_type": "code",
        "outputId": "02d16e6a-7cdb-429f-989a-0e3938e0da36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "cell_type": "code",
      "source": [
        "!ls training_checkpoints/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t    ckpt-3.data-00000-of-00001\n",
            "ckpt-1.data-00000-of-00001  ckpt-3.index\n",
            "ckpt-1.index\t\t    ckpt-4.data-00000-of-00001\n",
            "ckpt-2.data-00000-of-00001  ckpt-4.index\n",
            "ckpt-2.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2SmdzhWankCv",
        "colab_type": "code",
        "outputId": "293b86b5-97d5-48f3-b240-920e3bd6c334",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "np.argmax(np.array([0, 0, 1, 0, 0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "50G36H868Snm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}